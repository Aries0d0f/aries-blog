---
title: 電影論古今 - 模仿遊戲
date: 2018/03/08
categories:
- 白羊隨筆
tags: 
- USC
- 作業研究
- 電影論古今
photo: https://img.gagaoolala.com/media/94dc9ee8-567523-lg.jpg
---

## 前言：一場人類模仿機器的遊戲

對亞倫圖靈來說，與其說他是人，不如說他更像機器。劇中的圖靈機不僅扛起解密任務成功與否的重任、更是為了彌補圖靈心中無從消逝的感情缺憾。
電影過程中較為特別的是，三段不同時間線的劇情不斷相互交錯，圖靈的學生時期，參與解密任務的過程，以及圖靈離世前的最後日子，徹底剖析圖靈的內心故事，和他的悲劇人生，構起圖靈以「機器是否能思考？」為主軸的「模仿遊戲」。

<!-- more -->

## 從密碼學看圖靈機：為何我們需要大數據

劇中圖靈機成功關鍵，莫過於德軍電報末那句始終如一的「希特勒萬歲」，才能使圖靈機透過找關鍵的方式來破譯英格瑪。雖從今日角度看，那台用於破譯的圖靈機不過是將矩陣逆轉換的數學模型正規化、機械化罷了、根本談不上什麼人工智慧，頂多是基於密碼學推算出的通用演算法；不過其實現今正潮流的「機器學習」，簡單來說不過是透過現有的資料建立數學模型、且在解題過程中同時校正其原有之數學模型罷了。

機器學習這門學問，於傳統演算法相較，關鍵在於傳統演算法具有較強的專一性，只能針對同一類型之問題進行運算與剖析；但機器學習則會從問題本身及其解決問題過程來校正原有演算法使用之數學模型。但若現有數據量不足、過於離散甚至是無法被分析，就很難單靠機器學習來整理出有效的數學模型。由此可知，來源可靠且易於分析的大數據正是今日發展機器學習技術不可或缺的關鍵之一。

## 20 世紀末的 AI 夢：談談圖靈測試

AI，又稱人工智慧，大家都會掛在嘴邊講的這議題看似高深，但其實早在 20 世紀末就已風靡一時。那，為何這話題後來一度消極了、今日卻又浮出檯面？

科幻作家艾西莫夫曾提到機器人三大法則：

1. 機器人不得傷害人類，或看到人類受到傷害而袖手旁觀。
2. 機器人必須服從人類的命令，除非這條命令與第一條相矛盾。
3. 機器人必須保護自己，除非這種保護與以上兩條相矛盾。

儘管艾西莫夫定律作為策略而言比較方便且具有啟發性，但是並沒有提供研究人員和技術公司可以遵循的價值觀或者設計原則，也沒有告訴社會當 AI 和機器學習對經濟越來越多的構成產生推動時，人類必須帶入這下一個時代的能力是什麼。當時對於人工智慧這門科學聯想無外乎就是所謂的仿生機器人，又由於電影、小說將其誇大話，那時候許多學者都對人工智慧抱持著懷疑、倫理疑慮甚至是畏懼等等態度。但這夢沒做多久，人類就發現：他們想太多了，因為根本連所謂「人工智慧」都做不出來，更別談科幻題材裡具有攻擊性的「仿生機器人」。

圖靈於 1950 年提出一個關於判斷機器是否能夠思考的著名試驗、名為「圖靈測試」；這測驗目的，在於判斷某機器「是否能表現出與人等價或無法區分的智能」。

測試談話僅限於使用唯一的文本管道，例如鍵盤和螢幕，這樣的結果是不依賴於電腦把單詞轉換為音頻的能力（語音辨識技術）。測試內容簡略來說就是：如果一個人（代號C）使用測試對象皆理解的語言去詢問兩個他不能看見的對象任意一串問題。對象為：一個是正常思維的人（代號B）、一個是機器（代號A）。如果經過若干詢問以後，C 不能得出實質的區別來分辨 A 與 B 的不同，則此機器 A 通過圖靈測試。看似籠統簡單，但其實這上世紀的測試理論，在 2014 年才首度由英國雷丁大學系統工程學系宣布，來自俄國的尤金．古斯曼超級電腦在 Turing Test 2014 競賽首次通過這「圖靈測試」。

由此可知，20 世紀末的「人工智慧」在今日看起來是較為空虛、幻想而不切實際的。那麼今日的「人工智慧」又是如何積極發展的？

## 人工智能的未來：你該怎麼做

有學者提出，將 Artificial Intelligent 翻譯為「人工智慧」的定義不大好，應為「人工智能」，人工智慧容易預設其帶有人性且具有情緒；這也是 20 世紀末的「人工智慧」未達眾人期望的原因之一。

今日的人工智能透過不斷分析數據、解決問題、更新數學模型、再分析數據...等等循環過程，對各種「問題」透過「經驗」來做出具高度公平性的「決策」；可以想成是製造「數位裁判」來判定各種狀況。

與前面提及的許多案例相較、今日人工智慧多被企業用於提供更為方便、直覺的「服務」，
例如：Apple 的 Siri 透過語音辨識技術提供語音互動介面、Facebook 藉由人像辨識技術與興趣分析提供社交建議、Spotify 的每週新發現（Discovery Weekly）則是綜合音頻分析技術與使用者操作分析的精髓。

這些服務透過人工智能使得我們生活越來越方便，但也延伸其問題：企業為了打造這些「人工智能」服務，大數據是不可或缺的；但當「數據」是與我們日常生活息息相關、甚至涉及「個人隱私」時，想必每個人都不大願意吧？

多少都有過經驗，方才上街買個化妝品、回程滑手機時就直接在 Facebook 看到該廠商的產品廣告。往好處想是：「好方便！他真懂我。」但背後隱含的是，這些數據收集方式的不透明。你的手機難道真的是懂你才知道你剛剛去了哪、買了啥又喜歡什麼嗎？而這些斯在收集你的隱私資訊後，是否能妥善地保存這些個人隱私？而這些企業是否又會向某些政體妥協、洩漏你的個人數據？

另外，人工智能用在今日許多無人設備（etc. 無人車、工業 4.0 無人工廠）等狀況下，衍生出兩個主要問題：

1. 多少會面臨極端值的狀況需要判斷、如交通安全、公安；這時就牽涉到倫理問題。目前在這方面還具有許多爭議，牽扯其中包含決策演算及優生學，本文在此便不多提。
2. 失業率，人工智能逐漸取代掉許多基層員工的工作，許多企業選擇使用人工智能來代替現有雇員等方式來節省成本。

方便的科技必定會衍生出許多問題，但不是說因此就不去使用它；在使用這些服務前，不如先詳細的閱讀該服務之隱私條款與其數據保存相關政策，且在生活中找到多元自我專長來與人工智能和平共處，才是生活在 e 世代下、保護自己又活得進步的兩全其美之法。